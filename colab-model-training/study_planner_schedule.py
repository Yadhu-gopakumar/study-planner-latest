# -*- coding: utf-8 -*-
"""study_planner_schedule.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E_dR8bqekXe_Kx6r9ECqCR8qmrAQdoxL
"""

import pandas as pd
import random
import joblib
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

random.seed(42)
rows = []

# Generate 500 rows to give the model enough patterns to learn
for _ in range(500):
    difficulty = random.choice([1, 2, 3])   # 1-easy, 2-medium, 3-hard
    available_hours = round(random.uniform(1, 4), 1)
    days_left = random.randint(3, 45)
    previous_score = random.randint(30, 90)

    # --- RULE-GUIDED TARGET GENERATION ---

    # 1. Time Allocation Logic: Difficulty now heavily weights this
    # Hard subjects get a significant boost in requested hours
    # In your training script, make difficulty have a HUGE impact:
    time_alloc = round(
    (difficulty * 2.0) +  # Increased from 0.8
    (2.5 - available_hours * 0.3) +
    (20 / days_left),
    1
    )
    time_alloc = max(1.0, min(time_alloc, 6.0))

    # 2. Priority Logic: Lower value = Higher Priority (1 is top)
    # We start with a neutral priority and adjust based on features
    p_val = 3
    if days_left < 10: p_val -= 1         # Urgency boost
    if difficulty == 3: p_val -= 1        # Difficulty boost
    if previous_score < 50: p_val -= 1     # Struggle boost
    if difficulty == 1 and days_left > 20: p_val += 1 # Easy & far away = low priority

    priority = max(1, min(p_val, 5))

    # 3. Revision Frequency
    revision_freq = max(1, int((100 - previous_score + (difficulty * 5)) / 20))

    rows.append([difficulty, available_hours, days_left, previous_score, time_alloc, priority, revision_freq])

df = pd.DataFrame(rows, columns=["difficulty", "available_hours", "days_left", "previous_score", "time_alloc", "priority", "revision_freq"])
df.to_csv("study_planner_dataset.csv", index=False)

import pandas as pd
from sklearn.ensemble import RandomForestRegressor # Changed from DecisionTree
from sklearn.model_selection import train_test_split
import joblib

# Load dataset
# --- MODEL TRAINING ---

# Load dataset
df = pd.read_csv("study_planner_dataset.csv")

X = df[["difficulty", "available_hours", "days_left", "previous_score"]]
y = df[["time_alloc", "priority", "revision_freq"]]

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Use RandomForest for better granularity
model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    random_state=42
)

model.fit(X_train, y_train)

# Save the updated model
joblib.dump(model, "study_planner.pkl")
print("New Random Forest model trained and saved as study_planner.pkl")